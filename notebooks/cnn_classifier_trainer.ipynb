{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf65409-24bb-434f-97c5-9e89dd58b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "from keras.layers import Input, Add, Dense, BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import os\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39971eb2-d8c9-4493-a0eb-6d8980e3e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e71502-6cb0-4e46-be50-98a2808fb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 111, 111, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 54, 54, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 186624)           746496    \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               23888000  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,654,530\n",
      "Trainable params: 24,281,090\n",
      "Non-trainable params: 373,440\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 00:15:14.101611: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-23 00:15:14.513017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4154 MB memory:  -> device: 0, name: Quadro P2000, pci bus id: 0000:65:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "baseline_model = Sequential()\n",
    "# Adding Conv layer  \n",
    "baseline_model.add(Conv2D(filters=32, kernel_size = (3,3), activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "# Added max pooling layer\n",
    "baseline_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Added normalization layer\n",
    "baseline_model.add(BatchNormalization())\n",
    "baseline_model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "baseline_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "baseline_model.add(BatchNormalization())\n",
    "# Added flatten option\n",
    "baseline_model.add(Flatten())\n",
    "baseline_model.add(BatchNormalization())\n",
    "baseline_model.add(Dense(128,activation=\"relu\"))\n",
    "# Adding dropout of 50%\n",
    "baseline_model.add(tf.keras.layers.Dropout(0.5))\n",
    "baseline_model.add(Dense(2, activation=\"softmax\"))\n",
    "    \n",
    "baseline_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb2f232f-4b24-42a9-b02f-a2871d68d0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with split:  0.1\n",
      "Found 2238 images belonging to 2 classes.\n",
      "Found 248 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95326/4270682621.py:47: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 00:15:16.234292: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - ETA: 0s - loss: 2.5977 - accuracy: 0.8546\n",
      "Epoch 1: val_loss improved from inf to 10.06284, saving model to pneumonia-detection-model-via-loss-4-0.1.h5\n",
      "139/139 [==============================] - 46s 322ms/step - loss: 2.5977 - accuracy: 0.8546 - val_loss: 10.0628 - val_accuracy: 0.4958\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 2.4356 - accuracy: 0.8812\n",
      "Epoch 2: val_loss did not improve from 10.06284\n",
      "139/139 [==============================] - 43s 310ms/step - loss: 2.4356 - accuracy: 0.8812 - val_loss: 15.9036 - val_accuracy: 0.5083\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 2.1262 - accuracy: 0.8965\n",
      "Epoch 3: val_loss improved from 10.06284 to 6.15319, saving model to pneumonia-detection-model-via-loss-4-0.1.h5\n",
      "139/139 [==============================] - 45s 321ms/step - loss: 2.1262 - accuracy: 0.8965 - val_loss: 6.1532 - val_accuracy: 0.6792\n",
      "Epoch 4/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 2.1218 - accuracy: 0.8987\n",
      "Epoch 4: val_loss improved from 6.15319 to 1.40326, saving model to pneumonia-detection-model-via-loss-4-0.1.h5\n",
      "139/139 [==============================] - 45s 323ms/step - loss: 2.1218 - accuracy: 0.8987 - val_loss: 1.4033 - val_accuracy: 0.8958\n",
      "Epoch 5/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 2.0319 - accuracy: 0.8915\n",
      "Epoch 5: val_loss did not improve from 1.40326\n",
      "139/139 [==============================] - 43s 308ms/step - loss: 2.0319 - accuracy: 0.8915 - val_loss: 2.4072 - val_accuracy: 0.8125\n",
      "Epoch 6/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.7978 - accuracy: 0.8983\n",
      "Epoch 6: val_loss did not improve from 1.40326\n",
      "139/139 [==============================] - 43s 311ms/step - loss: 1.7978 - accuracy: 0.8983 - val_loss: 2.9891 - val_accuracy: 0.9125\n",
      "Epoch 7/20\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.4076 - accuracy: 0.9244\n",
      "Epoch 7: val_loss did not improve from 1.40326\n",
      "139/139 [==============================] - 43s 312ms/step - loss: 1.4076 - accuracy: 0.9244 - val_loss: 1.8383 - val_accuracy: 0.8542\n",
      "Training with split:  0.15\n",
      "Found 2114 images belonging to 2 classes.\n",
      "Found 372 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.0858 - accuracy: 0.8961\n",
      "Epoch 1: val_loss improved from inf to 3.48142, saving model to pneumonia-detection-model-via-loss-4-0.15.h5\n",
      "132/132 [==============================] - 45s 338ms/step - loss: 2.0858 - accuracy: 0.8961 - val_loss: 3.4814 - val_accuracy: 0.8424\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.0100 - accuracy: 0.9094\n",
      "Epoch 2: val_loss improved from 3.48142 to 1.22770, saving model to pneumonia-detection-model-via-loss-4-0.15.h5\n",
      "132/132 [==============================] - 45s 338ms/step - loss: 2.0100 - accuracy: 0.9094 - val_loss: 1.2277 - val_accuracy: 0.8832\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.5349 - accuracy: 0.8923\n",
      "Epoch 3: val_loss did not improve from 1.22770\n",
      "132/132 [==============================] - 43s 322ms/step - loss: 2.5349 - accuracy: 0.8923 - val_loss: 7.4018 - val_accuracy: 0.7391\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.8903 - accuracy: 0.9051\n",
      "Epoch 4: val_loss did not improve from 1.22770\n",
      "132/132 [==============================] - 42s 317ms/step - loss: 1.8903 - accuracy: 0.9051 - val_loss: 1.4621 - val_accuracy: 0.9076\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.9821 - accuracy: 0.9023\n",
      "Epoch 5: val_loss did not improve from 1.22770\n",
      "132/132 [==============================] - 43s 325ms/step - loss: 1.9821 - accuracy: 0.9023 - val_loss: 3.4768 - val_accuracy: 0.8614\n",
      "Training with split:  0.2\n",
      "Found 1990 images belonging to 2 classes.\n",
      "Found 496 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.3762 - accuracy: 0.8916\n",
      "Epoch 1: val_loss improved from inf to 2.24658, saving model to pneumonia-detection-model-via-loss-4-0.2.h5\n",
      "124/124 [==============================] - 45s 361ms/step - loss: 2.3762 - accuracy: 0.8916 - val_loss: 2.2466 - val_accuracy: 0.8871\n",
      "Epoch 2/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.6877 - accuracy: 0.9037\n",
      "Epoch 2: val_loss improved from 2.24658 to 1.11767, saving model to pneumonia-detection-model-via-loss-4-0.2.h5\n",
      "124/124 [==============================] - 44s 355ms/step - loss: 1.6877 - accuracy: 0.9037 - val_loss: 1.1177 - val_accuracy: 0.9012\n",
      "Epoch 3/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.9371 - accuracy: 0.9043\n",
      "Epoch 3: val_loss did not improve from 1.11767\n",
      "124/124 [==============================] - 42s 340ms/step - loss: 1.9371 - accuracy: 0.9043 - val_loss: 2.3368 - val_accuracy: 0.8952\n",
      "Epoch 4/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.6699 - accuracy: 0.9271\n",
      "Epoch 4: val_loss improved from 1.11767 to 0.88751, saving model to pneumonia-detection-model-via-loss-4-0.2.h5\n",
      "124/124 [==============================] - 44s 355ms/step - loss: 1.6699 - accuracy: 0.9271 - val_loss: 0.8875 - val_accuracy: 0.9395\n",
      "Epoch 5/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.7018 - accuracy: 0.9078\n",
      "Epoch 5: val_loss did not improve from 0.88751\n",
      "124/124 [==============================] - 42s 340ms/step - loss: 1.7018 - accuracy: 0.9078 - val_loss: 1.7655 - val_accuracy: 0.9153\n",
      "Epoch 6/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.7394 - accuracy: 0.9068\n",
      "Epoch 6: val_loss improved from 0.88751 to 0.45615, saving model to pneumonia-detection-model-via-loss-4-0.2.h5\n",
      "124/124 [==============================] - 44s 353ms/step - loss: 1.7394 - accuracy: 0.9068 - val_loss: 0.4561 - val_accuracy: 0.9577\n",
      "Epoch 7/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5408 - accuracy: 0.9174\n",
      "Epoch 7: val_loss did not improve from 0.45615\n",
      "124/124 [==============================] - 42s 336ms/step - loss: 1.5408 - accuracy: 0.9174 - val_loss: 1.0206 - val_accuracy: 0.9496\n",
      "Epoch 8/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.6286 - accuracy: 0.9164\n",
      "Epoch 8: val_loss did not improve from 0.45615\n",
      "124/124 [==============================] - 42s 341ms/step - loss: 1.6286 - accuracy: 0.9164 - val_loss: 2.6693 - val_accuracy: 0.8286\n",
      "Epoch 9/20\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4165 - accuracy: 0.9144\n",
      "Epoch 9: val_loss did not improve from 0.45615\n",
      "124/124 [==============================] - 42s 343ms/step - loss: 1.4165 - accuracy: 0.9144 - val_loss: 0.6953 - val_accuracy: 0.9274\n",
      "Training with split:  0.25\n",
      "Found 1865 images belonging to 2 classes.\n",
      "Found 621 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6247 - accuracy: 0.9162\n",
      "Epoch 1: val_loss improved from inf to 1.08358, saving model to pneumonia-detection-model-via-loss-4-0.25.h5\n",
      "116/116 [==============================] - 45s 384ms/step - loss: 1.6247 - accuracy: 0.9162 - val_loss: 1.0836 - val_accuracy: 0.9243\n",
      "Epoch 2/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6573 - accuracy: 0.9097\n",
      "Epoch 2: val_loss did not improve from 1.08358\n",
      "116/116 [==============================] - 41s 358ms/step - loss: 1.6573 - accuracy: 0.9097 - val_loss: 1.1359 - val_accuracy: 0.9227\n",
      "Epoch 3/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5639 - accuracy: 0.9135\n",
      "Epoch 3: val_loss improved from 1.08358 to 1.00575, saving model to pneumonia-detection-model-via-loss-4-0.25.h5\n",
      "116/116 [==============================] - 44s 380ms/step - loss: 1.5639 - accuracy: 0.9135 - val_loss: 1.0058 - val_accuracy: 0.9227\n",
      "Epoch 4/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5791 - accuracy: 0.9243\n",
      "Epoch 4: val_loss did not improve from 1.00575\n",
      "116/116 [==============================] - 43s 369ms/step - loss: 1.5791 - accuracy: 0.9243 - val_loss: 2.2325 - val_accuracy: 0.8569\n",
      "Epoch 5/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5446 - accuracy: 0.9064\n",
      "Epoch 5: val_loss improved from 1.00575 to 0.77603, saving model to pneumonia-detection-model-via-loss-4-0.25.h5\n",
      "116/116 [==============================] - 44s 379ms/step - loss: 1.5446 - accuracy: 0.9064 - val_loss: 0.7760 - val_accuracy: 0.9359\n",
      "Epoch 6/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2812 - accuracy: 0.9248\n",
      "Epoch 6: val_loss did not improve from 0.77603\n",
      "116/116 [==============================] - 42s 363ms/step - loss: 1.2812 - accuracy: 0.9248 - val_loss: 0.8563 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2145 - accuracy: 0.9216\n",
      "Epoch 7: val_loss did not improve from 0.77603\n",
      "116/116 [==============================] - 42s 361ms/step - loss: 1.2145 - accuracy: 0.9216 - val_loss: 3.0117 - val_accuracy: 0.8322\n",
      "Epoch 8/20\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4817 - accuracy: 0.9005\n",
      "Epoch 8: val_loss did not improve from 0.77603\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 1.4817 - accuracy: 0.9005 - val_loss: 0.8015 - val_accuracy: 0.9178\n",
      "Training with split:  0.3\n",
      "Found 1741 images belonging to 2 classes.\n",
      "Found 745 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.9217\n",
      "Epoch 1: val_loss improved from inf to 0.50288, saving model to pneumonia-detection-model-via-loss-4-0.3.h5\n",
      "108/108 [==============================] - 45s 410ms/step - loss: 1.2684 - accuracy: 0.9217 - val_loss: 0.5029 - val_accuracy: 0.9443\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1558 - accuracy: 0.9200\n",
      "Epoch 2: val_loss did not improve from 0.50288\n",
      "108/108 [==============================] - 42s 388ms/step - loss: 1.1558 - accuracy: 0.9200 - val_loss: 1.1525 - val_accuracy: 0.9171\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1822 - accuracy: 0.9159\n",
      "Epoch 3: val_loss did not improve from 0.50288\n",
      "108/108 [==============================] - 42s 386ms/step - loss: 1.1822 - accuracy: 0.9159 - val_loss: 0.7217 - val_accuracy: 0.9565\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1606 - accuracy: 0.9223\n",
      "Epoch 4: val_loss did not improve from 0.50288\n",
      "108/108 [==============================] - 42s 389ms/step - loss: 1.1606 - accuracy: 0.9223 - val_loss: 0.8944 - val_accuracy: 0.9402\n",
      "Training with split:  0.35\n",
      "Found 1617 images belonging to 2 classes.\n",
      "Found 869 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.2557 - accuracy: 0.9232\n",
      "Epoch 1: val_loss improved from inf to 0.59021, saving model to pneumonia-detection-model-via-loss-4-0.35.h5\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 1.2557 - accuracy: 0.9232 - val_loss: 0.5902 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.1962 - accuracy: 0.9138\n",
      "Epoch 2: val_loss did not improve from 0.59021\n",
      "101/101 [==============================] - 41s 408ms/step - loss: 1.1962 - accuracy: 0.9138 - val_loss: 0.8607 - val_accuracy: 0.9178\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.1921 - accuracy: 0.9188\n",
      "Epoch 3: val_loss did not improve from 0.59021\n",
      "101/101 [==============================] - 41s 408ms/step - loss: 1.1921 - accuracy: 0.9188 - val_loss: 0.7489 - val_accuracy: 0.9178\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.2562 - accuracy: 0.9119\n",
      "Epoch 4: val_loss did not improve from 0.59021\n",
      "101/101 [==============================] - 41s 410ms/step - loss: 1.2562 - accuracy: 0.9119 - val_loss: 4.5844 - val_accuracy: 0.8032\n"
     ]
    }
   ],
   "source": [
    "folder = \"./chest_xray\"\n",
    "train_path = folder + '/train'\n",
    "model_histories = []\n",
    "model_scores = []\n",
    "models = []\n",
    "split_coefs = [0.1,0.15,0.20,0.25,0.3,0.35]\n",
    "for split_coef in split_coefs:\n",
    "    print(\"Training with split: \",str(split_coef))\n",
    "    model = baseline_model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    data_generator = ImageDataGenerator(preprocessing_function=tf.image.per_image_standardization,featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  \n",
    "            featurewise_std_normalization=False,  \n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,  \n",
    "            rotation_range=10, \n",
    "            zoom_range = 0.1, \n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,  \n",
    "            horizontal_flip=False,  \n",
    "            vertical_flip=False,\n",
    "            validation_split = split_coef)\n",
    "\n",
    "    batch_size= 16\n",
    "\n",
    "    train_generator = data_generator.flow_from_directory(directory=train_path, target_size=(224,224), classes=[\"normal\",\"pneumonia\"], batch_size=batch_size,subset='training')\n",
    "    validation_generator = data_generator.flow_from_directory(directory=train_path, target_size=(224,224), classes=[\"normal\",\"pneumonia\"], batch_size=batch_size,subset='validation')\n",
    "\n",
    "    filepath = \"pneumonia-detection-model-via-loss-4-\" + str(split_coef) + \".h5\"\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                                 monitor=\"val_loss\",\n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True,\n",
    "                                 mode=\"auto\")\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0, patience=3, verbose=0,\n",
    "        mode='auto', baseline=None, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_generator.samples // batch_size,\n",
    "        validation_data = validation_generator, \n",
    "        validation_steps = validation_generator.samples // batch_size,\n",
    "        epochs = 20,\n",
    "        verbose = 1,\n",
    "        callbacks=[checkpoint,early_stopping]\n",
    "    )\n",
    "    \n",
    "    best_model_loss = history.history['val_loss'][np.argmin(history.history['val_loss'])]\n",
    "    model_scores.append(best_model_loss)\n",
    "    models.append(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63cef804-25c9-4f65-a26e-82b38567ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Best model is:  pneumonia-detection-model-via-loss-4-0.2.h5\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(model_scores))\n",
    "split_coefs = [0.1,0.15,0.20,0.25,0.3,0.35]\n",
    "best_split = split_coefs[np.argmin(model_scores)]\n",
    "best_model = models[np.argmin(model_scores)]\n",
    "print(\"Best model is: \", models[np.argmin(model_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210e92e8-74bb-42af-a3c3-090575b2c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4032646417617798, 1.227704644203186, 0.4561465084552765, 0.7760316729545593, 0.5028775334358215, 0.5902078747749329]\n"
     ]
    }
   ],
   "source": [
    "print(model_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
