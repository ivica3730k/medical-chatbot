<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>chatbot.QAEngine API documentation</title>
<meta name="description" content="QAPair module used to perform similarity-based question lookup to provide the user with the best possible answer.
The similarity-based
functionality â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>chatbot.QAEngine</code></h1>
</header>
<section id="section-intro">
<p>QAPair module used to perform similarity-based question lookup to provide the user with the best possible answer.
The similarity-based
functionality is based on a set of pre-defined Q/As in a CSV file.
The similarity-based component is based on the bag-of-words model, tf/idf, and cosine similarity.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
QAPair module used to perform similarity-based question lookup to provide the user with the best possible answer.
The similarity-based  functionality is based on a set of pre-defined Q/As in a CSV file.
The similarity-based component is based on the bag-of-words model, tf/idf, and cosine similarity.
&#34;&#34;&#34;

import csv
import logging

import autocorrect
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(level=logging.INFO)  # change critical to info to display information

# Initialize the spell checker we are going to use to autocorrect are questions and
# answers when we load them into our QRPair class
_spell = autocorrect.Speller(&#34;en&#34;)
vectorizer = TfidfVectorizer(stop_words=&#39;english&#39;)

_questions = []
_answers = []


def load_qa_pair(question: str, answer: str) -&gt; None:
    &#34;&#34;&#34;
    Load the QA pair into QAPair module

    Args:
        question: Question
        answer: Answer
    &#34;&#34;&#34;
    _questions.append(_spell(BeautifulSoup(question, &#34;lxml&#34;).get_text(strip=True)).lower())
    _answers.append((BeautifulSoup(answer, &#34;lxml&#34;).get_text(strip=True)))


def _get_real_question_id(question: str, confidence_threshold: float = 0.00) -&gt; (bool, int):
    &#34;&#34;&#34;
    Perform the similarity-based lookup for the real question from our QA list based on the user-entered question.

    Similarity based lookup based on bag of words and cosine similarity is used to determine the question the user most
    likely wanted to ask. User question is appended to the question list and sparse matrix is created and passed to the
    pandas data frame. Afterwards the cosine similarity is calculated using sklearn, our question is removed from
    the question list and similarity list (as it&#39;s score is always 1.00). Finally, the index with biggest
    score is returned. Note, in order to exclude useless answers, the confidence threshold is applied.

    Args:
        question: User question to apply similarity-based lookup on
        confidence_threshold: Confidence threshold for cosine-similarity. Used to exclude useless answer


    Returns: Validity status, Index of question in _questions list best matching to User question input
    &#34;&#34;&#34;
    question = _spell(question)
    _questions.append(question)
    sparse_matrix = vectorizer.fit_transform(_questions)
    doc_term_matrix = sparse_matrix.todense()
    df = pd.DataFrame(doc_term_matrix)
    cs = cosine_similarity(df, df)[len(_questions) - 1]
    cs = np.delete(cs, -1)  # remove our question from the scores
    if logging.INFO &gt;= logging.root.level:
        print(cs)
    _questions.pop()
    index = np.argmax(cs)
    if cs[index] &gt;= confidence_threshold:
        return True, index
    else:
        return False, index


def get_answer(question: str, confidence_threshold: float = 0.25) -&gt; (bool, str):
    &#34;&#34;&#34;
    Interface function used to obtain the answer for the question provided, running similarity-based lookup
    in the background.

    Args:
        question: User question
        confidence_threshold: Confidence threshold for cosine-similarity. Used to exclude useless answer

    Returns:
        Validity status ,answer to user question
    &#34;&#34;&#34;
    if not _questions:
        logging.critical(&#34;Trying to get answer without QA dataset loaded&#34;)
        return False, &#34;&#34;
    question = question.lower()
    question_corrected = _spell(question)
    if question_corrected != question:
        logging.info(&#34;Corrected {0} into {1}&#34;.format(question, question_corrected))
        question = question_corrected
    ok, question_id = _get_real_question_id(question, confidence_threshold)
    if ok:
        return True, _answers[question_id]
    else:
        return False, &#34;&#34;


def load_qa_csv(filepath: str) -&gt; None:
    &#34;&#34;&#34;
    Function used to load qa csv file into module

    Args:
        filepath: Path to csv file
    &#34;&#34;&#34;
    with open(filepath, encoding=&#34;latin&#34;) as csvfile:
        for l in csv.reader(csvfile, quotechar=&#39;&#34;&#39;, delimiter=&#39;,&#39;,
                            quoting=csv.QUOTE_ALL, skipinitialspace=True):
            load_qa_pair(l[0], l[1])


def print_qa_pairs() -&gt; None:
    &#34;&#34;&#34;
    Print QA Pairs for debug purposes
    &#34;&#34;&#34;
    for i in range(0, len(_answers)):
        print(_questions[i], &#39;&gt;&gt;&#39;, _answers[i])


# Some code to make private members visible in documentation
__pdoc__ = {name: True
            for name, obj in globals().items()
            if name.startswith(&#39;_&#39;) and callable(obj)}</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="chatbot.QAEngine._get_real_question_id"><code class="name flex">
<span>def <span class="ident">_get_real_question_id</span></span>(<span>question:Â str, confidence_threshold:Â floatÂ =Â 0.0) â€‘>Â (<classÂ 'bool'>,Â <classÂ 'int'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the similarity-based lookup for the real question from our QA list based on the user-entered question.</p>
<p>Similarity based lookup based on bag of words and cosine similarity is used to determine the question the user most
likely wanted to ask. User question is appended to the question list and sparse matrix is created and passed to the
pandas data frame. Afterwards the cosine similarity is calculated using sklearn, our question is removed from
the question list and similarity list (as it's score is always 1.00). Finally, the index with biggest
score is returned. Note, in order to exclude useless answers, the confidence threshold is applied.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>question</code></strong></dt>
<dd>User question to apply similarity-based lookup on</dd>
<dt><strong><code>confidence_threshold</code></strong></dt>
<dd>Confidence threshold for cosine-similarity. Used to exclude useless answer</dd>
</dl>
<p>Returns: Validity status, Index of question in _questions list best matching to User question input</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def _get_real_question_id(question: str, confidence_threshold: float = 0.00) -&gt; (bool, int):
    &#34;&#34;&#34;
    Perform the similarity-based lookup for the real question from our QA list based on the user-entered question.

    Similarity based lookup based on bag of words and cosine similarity is used to determine the question the user most
    likely wanted to ask. User question is appended to the question list and sparse matrix is created and passed to the
    pandas data frame. Afterwards the cosine similarity is calculated using sklearn, our question is removed from
    the question list and similarity list (as it&#39;s score is always 1.00). Finally, the index with biggest
    score is returned. Note, in order to exclude useless answers, the confidence threshold is applied.

    Args:
        question: User question to apply similarity-based lookup on
        confidence_threshold: Confidence threshold for cosine-similarity. Used to exclude useless answer


    Returns: Validity status, Index of question in _questions list best matching to User question input
    &#34;&#34;&#34;
    question = _spell(question)
    _questions.append(question)
    sparse_matrix = vectorizer.fit_transform(_questions)
    doc_term_matrix = sparse_matrix.todense()
    df = pd.DataFrame(doc_term_matrix)
    cs = cosine_similarity(df, df)[len(_questions) - 1]
    cs = np.delete(cs, -1)  # remove our question from the scores
    if logging.INFO &gt;= logging.root.level:
        print(cs)
    _questions.pop()
    index = np.argmax(cs)
    if cs[index] &gt;= confidence_threshold:
        return True, index
    else:
        return False, index</code></pre>
</details>
</dd>
<dt id="chatbot.QAEngine.get_answer"><code class="name flex">
<span>def <span class="ident">get_answer</span></span>(<span>question:Â str, confidence_threshold:Â floatÂ =Â 0.25) â€‘>Â (<classÂ 'bool'>,Â <classÂ 'str'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface function used to obtain the answer for the question provided, running similarity-based lookup
in the background.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>question</code></strong></dt>
<dd>User question</dd>
<dt><strong><code>confidence_threshold</code></strong></dt>
<dd>Confidence threshold for cosine-similarity. Used to exclude useless answer</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Validity status ,answer to user question</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_answer(question: str, confidence_threshold: float = 0.25) -&gt; (bool, str):
    &#34;&#34;&#34;
    Interface function used to obtain the answer for the question provided, running similarity-based lookup
    in the background.

    Args:
        question: User question
        confidence_threshold: Confidence threshold for cosine-similarity. Used to exclude useless answer

    Returns:
        Validity status ,answer to user question
    &#34;&#34;&#34;
    if not _questions:
        logging.critical(&#34;Trying to get answer without QA dataset loaded&#34;)
        return False, &#34;&#34;
    question = question.lower()
    question_corrected = _spell(question)
    if question_corrected != question:
        logging.info(&#34;Corrected {0} into {1}&#34;.format(question, question_corrected))
        question = question_corrected
    ok, question_id = _get_real_question_id(question, confidence_threshold)
    if ok:
        return True, _answers[question_id]
    else:
        return False, &#34;&#34;</code></pre>
</details>
</dd>
<dt id="chatbot.QAEngine.load_qa_csv"><code class="name flex">
<span>def <span class="ident">load_qa_csv</span></span>(<span>filepath:Â str) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to load qa csv file into module</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filepath</code></strong></dt>
<dd>Path to csv file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_qa_csv(filepath: str) -&gt; None:
    &#34;&#34;&#34;
    Function used to load qa csv file into module

    Args:
        filepath: Path to csv file
    &#34;&#34;&#34;
    with open(filepath, encoding=&#34;latin&#34;) as csvfile:
        for l in csv.reader(csvfile, quotechar=&#39;&#34;&#39;, delimiter=&#39;,&#39;,
                            quoting=csv.QUOTE_ALL, skipinitialspace=True):
            load_qa_pair(l[0], l[1])</code></pre>
</details>
</dd>
<dt id="chatbot.QAEngine.load_qa_pair"><code class="name flex">
<span>def <span class="ident">load_qa_pair</span></span>(<span>question:Â str, answer:Â str) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Load the QA pair into QAPair module</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>question</code></strong></dt>
<dd>Question</dd>
<dt><strong><code>answer</code></strong></dt>
<dd>Answer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_qa_pair(question: str, answer: str) -&gt; None:
    &#34;&#34;&#34;
    Load the QA pair into QAPair module

    Args:
        question: Question
        answer: Answer
    &#34;&#34;&#34;
    _questions.append(_spell(BeautifulSoup(question, &#34;lxml&#34;).get_text(strip=True)).lower())
    _answers.append((BeautifulSoup(answer, &#34;lxml&#34;).get_text(strip=True)))</code></pre>
</details>
</dd>
<dt id="chatbot.QAEngine.print_qa_pairs"><code class="name flex">
<span>def <span class="ident">print_qa_pairs</span></span>(<span>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Print QA Pairs for debug purposes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_qa_pairs() -&gt; None:
    &#34;&#34;&#34;
    Print QA Pairs for debug purposes
    &#34;&#34;&#34;
    for i in range(0, len(_answers)):
        print(_questions[i], &#39;&gt;&gt;&#39;, _answers[i])</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="chatbot" href="index.html">chatbot</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="chatbot.QAEngine._get_real_question_id" href="#chatbot.QAEngine._get_real_question_id">_get_real_question_id</a></code></li>
<li><code><a title="chatbot.QAEngine.get_answer" href="#chatbot.QAEngine.get_answer">get_answer</a></code></li>
<li><code><a title="chatbot.QAEngine.load_qa_csv" href="#chatbot.QAEngine.load_qa_csv">load_qa_csv</a></code></li>
<li><code><a title="chatbot.QAEngine.load_qa_pair" href="#chatbot.QAEngine.load_qa_pair">load_qa_pair</a></code></li>
<li><code><a title="chatbot.QAEngine.print_qa_pairs" href="#chatbot.QAEngine.print_qa_pairs">print_qa_pairs</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>